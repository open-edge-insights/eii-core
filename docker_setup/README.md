Docker compose setup of IEI solution:
=====================================
--------------------------------------

The setup instructions below assume the OS is installed and ready.
If Clearlinux is used, please follow the [docker_setup/clear_linux_setup_guide.md](clear_linux_setup_guide.md) for installing the Clearlinux OS.
Rest of the README will mention steps to be followed in Ubuntu for setting up the Edge insights platform.

## <u>Pre-requisities</u>:

1. Install latest docker cli/docker daemon by following [https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce](https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce). Follow **Install using the repository** and **Install Docker CE (follow first 2 steps)** sections there. Also, follow the manage docker as a non-root user section at [https://docs.docker.com/install/linux/linux-postinstall/](https://docs.docker.com/install/linux/linux-postinstall/) to run docker without sudo

2. Please follow the below steps only if the node/system on which the docker setup is tried out is running behind a HTTP proxy server. If that's not the case, this step can be skipped.

    * Configure proxy settings for docker client to connect to internet and for containers to access internet by following [https://docs.docker.com/network/proxy/](https://docs.docker.com/network/proxy/). One can copy the below json object to ~/.docker/config.json (**Note**: `Depending on the geo location where the system is setup, please use the proxy settings of that geo. This change may not be needed in  non-proxy environment`):

        ```
        {
            "proxies":
                {
                    "default":
                    {
                        "httpProxy": "http://proxy.iind.intel.com:911",
                        "httpsProxy": "http://proxy.iind.intel.com:911",
                        "noProxy": "127.0.0.1,localhost,*.intel.com"
                    }
                }
        }
        ```

    * Configure proxy settings for docker daemon by following the steps at [https://docs.docker.com/config/daemon/systemd/#httphttps-proxy](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy). Use the values for http proxy and https proxy as used above (**Note**: `Depending on the geo location where the system is setup, please use the proxy settings of that geo. This change may not be needed in  non-proxy environment`)

    * If you still see issues of not being able to access internet from container, please update /etc/resolv.conf with correct configuration.

        ```
        A. Ubuntu 16.04 and earlier

            For Ubuntu 16.04 and earlier, /etc/resolv.conf was dynamically generated by NetworkManager.

            Comment out the line dns=dnsmasq (with a #) in /etc/NetworkManager/NetworkManager.conf

            Restart the NetworkManager to regenerate /etc/resolv.conf :
            sudo systemctl restart network-manager

            Verify on the host: cat /etc/resolv.conf

        B. Ubuntu 18.04 and later

            Ubuntu 18.04 changed to use systemd-resolved to generate /etc/resolv.conf. Now by default it uses a local DNS cache 127.0.0.53. That will not work inside a container, so Docker will default to Google's 8.8.8.8 DNS server, which may break for people behind a firewall.

            /etc/resolv.conf is actually a symlink (ls -l /etc/resolv.conf) which points to /run/systemd/resolve/stub-resolv.conf (127.0.0.53) by default in Ubuntu 18.04.

            Just change the symlink to point to /run/systemd/resolve/resolv.conf, which lists the real DNS servers:
            sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf

            Verify on the host: cat /etc/resolv.conf
        ```

3. Install `docker-compose` tool by following this [https://docs.docker.com/compose/install/#install-compose](https://docs.docker.com/compose/install/#install-compose)

4. Make sure host machine and docker daemon are configured with below security recommendations. [docker_security_recommendation.md](docker_security_recommendation.md)
   Note: This step is required for the final production setup for full security.

### ** IEI pre-requisites **

1. Copy the PCB demo and classification sample test videos to the `test_videos` folder under `IEdgeInsights/docker_setup/` by using the following commands:

    ```sh
    cd IEdgeInsights/docker_setup/test_videos
    wget https://gitlab.devtools.intel.com/uploads/-/system/personal_snippet/289/4e92aff009c16f676b51f0ac744364ca/pcb_d2000.avi --no-proxy

    wget https://gitlab.devtools.intel.com/uploads/-/system/personal_snippet/289/b9bd04be5230957bc313bad1ca65beb0/classification_vid.avi --no-proxy
    ```

2. Clone the a locally maintained [kapacitor repository](https://gitlab.devtools.intel.com/Indu/IEdgeInsights/kapacitor.git) inside the `IEdgeInsights` folder.

    **NOTE**: Please use the git repo of kapacitor as is, the script `build.py` is dependent on that.

3. #### [Requirement for video analytics container]
     Download the full package for OpenVINO toolkit for Linux version "2019 R1.0.1" from the official website (https://software.intel.com/en-us/openvino-toolkit/choose-download/free-download-linux) and extract it inside IEdgeInsights/DataAnalytics/VideoAnalytics. Post this step a directory named `l_openvino_toolkit_xxxxx/` will be present inside VideoAnalytics directory.

  > **NOTE**: Make sure there is always one `l_openvino_toolkit_xxxxx/` folder under IEdgeInsights/DataAnalytics/
  > VideoAnalytics folder as we are adding `l_openvino_toolkit_*` into Dockerfile which could result in
  > build failure of VideoAnalytics container if there are multiple openvino sdk's in there especially the old ones

4. To work with Basler Source Plugin clone [basler-source-plugin](https://gitlab.devtools.intel.com/Indu/IEdgeInsights/basler-source-plugin.git) inside the `IEdgeInsights` folder.

## Steps to setup IEI solution on test/factory system

### <u>Configuration</u>

1. All configurable options for IEI goes into [.env](.env) file.
2. All the provisioning related containers goes into [provision-compose.yml](provision-compose.yml)    and IEI containers goes into [docker-compose.yml](docker-compose.yml)
3. Provide the right value for "CONFIG_FILE" in [.env](.env) file for video source.
   1. [factory_pcbdemo.json](./config/algo_config/factory_pcbdemo.json) - value to be used if working with a defect video file for the sample pcbdemo application
   2. [factory_basler.json](./config/algo_config/factory_basler.json) - value to be used if working with single basler camera setup
   3. [factory_rtsp_hikvision_ds2.json](./config/algo_config/factory_rtsp_hikvision_ds2.json) - value to be used if working with physical hikvision ds2 rtsp camera setup
   4. [factory_rtsp_cvlc.json](./config/algo_config/factory_rtsp_cvlc.json) - value to be used if working with stimulated cvlc rtsp camera setup
   5. [factory_usb.json](./config/algo_config/factory_usb.json) - value to be used if working with usb webcam.
   6. [factory_multi_cam.json](./config/algo_config/factory_multi_cam.json) - value to be used if working with multiple streams coming from the same or diff sources (rtsp,                                                                basler, usb)
   7. [factory_classification.json](./config/algo_config/factory_classification.json) - value to be used if working with the sample classification application

4. `<Factory control App>`Follow [FactoryControlApp/README.md](../FactoryControlApp/README.md) for ingestion    
   configuration over MQTT, alarm light and reset button
5. Provide the right value for TPM_ENABLE in [.env](.env) file for using TPM feature. This configuration should be used when the IEI is expected to leverage TPM for storing vault specific secret credentials. If one sets it to false, certain credentials are stored in file system.
    1. `true` -  for enabling the tpm to store credentials
    2. `false` - for disabling the tpm

    **NOTE**: Please use `TPM_ENABLE=true` only on systems where TPM hardware is present OR TPM is enabled using PTT Firmware in the BIOS.

6. Algo configuration:
    * The trigger and classifier algorithm configuration is available in `factory_pcbdemo.json`, `factory_basler.json`, `factory_rtsp.json` or `factory_multi_cam.json` for the sample pcbdemo application and in `factory_classification.json` for the sample classification algorithm. The choice of the algorithm and the parameters accepted by it can be configured in these files.
    Refer [VideoIngestion/README](../VideoIngestion/README.md) for more details

7. **Selective container build and run.**

   By default IEI will build and run video analytics services. If you want to run selective services,please
   provide the right value for "CONFIG_FILE" in [.env](.env) file for IEI_SERVICES.
   1. [services_video.json](./config/services_video.json) - value to be used if working with a video analytics use case.
   2. [services_pointdata.json](./config/services_pointdata.json) - value to be used if working with point data analytics use case.
   3. [services_all.json](./config/services_all.json) - value to be used if working with both pointdata and video analytics.

   **NOTE** For doing MQTT point data ingestion, please follow [DataAnalytics/README.md](../DataAnalytics/README.md)

   4. If you want to add your own services to IEI, Along with core services, please add your
   service to json file mentioned [.env](.env) with the dockerignore file. if there is no dockerignore file, please mention .dockerignore.common.

   ```sh
   "iei_services": [
        {
            "name": "my_custom_service",
            "dockerignore": ".dockerignore.common"

        }]
   ```

8. **Enabling Development Mode.**

   Inorder to enable Development mode, **DEV_MODE** variable in .env need to be changed as mentioned below.
   1. DEV_MODE=false (default) - This mode runs all container in secured mode.
   2. DEV_MODE=true -  For disabling security & enabling trigger algo modification dynamically in host machine

      **NOTE**:
      * If Development mode is set true then provisioning steps should be skipped.
      * Any configuration changes in the  [provision_config.json](./config/provision_config.json) will be effective in DEV mode
        only when the provisioning step is run again.
      * If influxDB credentials are changed in the provision_config.json, then `${IEI_INSTALL_PATH}/data/` folder should be deleted in order to take the new credentials into effect.  

9. The inferencing by default will happen on `CPU`. With EIS v1.0.3 version onwards, there is support added
   for running inference on `Myriad` and `HDDL` devices as well by accepting device type (“CPU”|”GPU”|”MYRIAD”|”HDDL”) from factory json files in [algo_config](../algos/algo_config/) folder. To run on HDDL devices, make sure to uncomment the below section of code in [DataAnalytics/VideoAnalytics/va_classifier_start.sh](../DataAnalytics/VideoAnalytics/va_classifier_start.sh).

    ```sh
    #Uncomment these lines if you are using HDDL
    #$HDDL_INSTALL_DIR/bin/hddldaemon &
    #sleep 20
    ```

### <u>Build & Installation</u>

1. Building the iei containers from source

    * Follow below steps to generate certificates, provision and build/start IEI.

        1. Certificates generation:

            Follow [cert-tool/README.md](../cert-tool/README.md) to generate the required certificates/keys.

        2. Provision the secrets to Vault (**present working dir - `<IEdgeInsights>/docker_setup/`**)

            Run the script:
            ```sh
            sudo make provision CERT_PATH=<PATH_TO_CERTIFICATES_DIRECTORY> | tee provision_startup.txt
                E.g. sudo make provision CERT_PATH=../cert-tool/Certificates/
            ```
            This will take the inputs from `provision_config.json` & certificates, following which it seal the secrets into the Vault.
            It is responsibility of the Admin to remove the source directory wherein certificates exist.

            **Note**: If the admin wants to update the secrets in the vault, a re-provisioning step needs to be done like below:
            ```sh
            <Take back up of image store, influx or any other data if it is needed in future because provisioning steps deletes all of it>
            <Update the new values into provision_config.json & custom certificates directory if necessary>
            sudo make provision CERT_PATH=<PATH_TO_CERTIFICATES_DIRECTORY> | tee provision_startup.txt
            ```

        3. Build and run IEI images as per the dependency order (**present working dir - `<IEdgeInsights>/docker_setup/`**)

            For factory deployments, we want IEI to come up automatically on system boot. For doing this, run the script: **This step will unsinstall any previous version of IEI. This step does not need a provisioning step to be executed first.**

            ```sh
            sudo make install CERT_PATH=<PATH_TO_CERTIFICATES_DIRECTORY> | tee setup_iei_logs.txt
                E.g. sudo make install CERT_PATH=../cert-tool/Certificates/
            ```

            This will install IEI as a systemd service in Ubuntu. Post installation, IEI can be started / stopped using commands:

            ```sh
            sudo systemctl stop iei
            sudo systemctl start iei
            ```

            **Note**:
            Developers can make use of the below script:

            ```sh
            sudo make build run | tee compose_startup.txt
            ```

            This will not make a systemd service and just build and start IEI.
            Verify all IEI containers coming up and working by following the `Post Installation Verification` steps.

        4. This is an `optional` step where in IEI user wants to build and run IEI images using a DOCKER REGISTRY. This is very helpful
           when one wants to pull and deploy docker images directly from a docker registry instead of building in every system.

            To install IEI in factory from a DOCKER REGISTRY, only [<IEdgeInsights>/docker_setup/](../docker_setup/) folder needs to be copied to
            target system. Once copied please use below commands. **This step will unsinstall any previous version of IEI. This step does not need a provisioning step to be executed first.** Follow [cert-tool/README.md](../cert-tool/README.md) to generate the required certificates/keys first before installing from registry.

            ```sh
            sudo make install-registry CERT_PATH=<PATH_TO_CERTIFICATES_DIRECTORY>  DOCKER_REGISTRY=<IP ADDRESS or URL>
            ```

            To generate client external libs distribution package using Docker registry, please use below option

            ```sh
            sudo make distlibs-registry DOCKER_REGISTRY=<IP ADDRESS or URL>
            ```

           > **Note**:
            > 1. To build locally and push the images to registry, please use below option. **Entire IEdgeInsights folder needs to be present on the system from where images are pushed to registry**

            ```sh
            sudo make build push DOCKER_REGISTRY=<IP ADDRESS or URL>
            ```

            > 2. Developers can make use of the below script to run locally from a Docker registry:

            ```sh
            sudo make pull run  DOCKER_REGISTRY=<IP ADDRESS or URL> | tee compose_startup.txt
            ```

             > **Note**:
              * Please use below command to run a local Docker Registry server

              ```sh
              docker run -d -p 5000:5000 --restart=always --name registry registry:2
              ```

              * To use local registry without using secure TLS, please insert below key in `/etc/docker/daemon.json`

                    ```sh
                    "insecure-registries" : ["<IP ADDRESS / REGISTRY URL>"]
                    ```

              * Please refer to [official docker documentation](https://docs.docker.com/registry/deploying/) for more details on Docker Registry.

    > **Note**:
    > 1. Please note: `cp -f resolv.conf /etc/resolv.conf` line in `compose_startup.sh` needs to be commented in non-proxy environment before
    > starting it off.

2. Follow [iei-simple-visualizer](https://gitlab.devtools.intel.com/Indu/IEdgeInsights/iei-simple-visualizer.git) to run either it as a containerized app or natively

   **Note**: `iei-simple-visualizer` is a sample python gRPC/OPCUA client created by us for demonstrating the usage of `ImageStore` and `DataBusAbstraction` distribution libs package. If one wants to develop a similar app, one can make use of the `ImageStore` and `DataBusAbstraction` python clients available at `/opt/intel/iei/dist_libs` to receive classified images and their metadata.

3. If working with video file i.e, `CONFIG_FILE` is set to `factory_pcbdemo.json` for the sample pcbdemo application and `factory_classification.json` for the sample classification algorithm in [.env](.env), by default the video frames are ingested in loop by
   `ia_video_ingestion` container. One can also restart ia_video_ingestion container manually by running:
   `docker restart ia_video_ingestion`

### Post Installation Verification

1. To check if all the IEI images are built successfully, use cmd: `docker images|grep ia` and
   all containers are running, use cmd: `docker ps` (`one should see all the dependency containers and IEI containers up and running`). If you see issues where the build is failing due to non-reachability to Internet, please ensure you have correctly configured proxy settings and restarted docker service. Even after doing this, if you are running into the same issue, please add below instrcutions to all the dockerfiles in `docker_setup\dockerfiles` at the top after the LABEL instruction and retry the building IEI images:

    ```sh
    ENV http_proxy http://proxy.iind.intel.com:911
    ENV https_proxy http://proxy.iind.intel.com:911
    ```

2. `docker ps` should list the below containers in IEI stack:
    * Dependency containers: log rotate (`ia_log_rotate`)
    * IEI core containers:  DataAgent (`ia_data_agent`), imagestore (`ia_imagestore`), Video Ingestion (`ia_video_ingestion`),
      Data Analytics (`ia_data_analytics`), Telegraf based Data ingestion (`ia_telegraf`) and Factory Control App (`ia_factoryctrl_app`)

    **Note**: If any of the above containers are not listed, always use cmd: `sudo tail -f /opt/intel/iei/logs/consolidatedLogs/iei.log` to find out the reason for container failure

3. To verify if the data pipeline withing IEI is working fine i.e., from ingestion -> classification -> publishing classifed metadata onto the
   databus, then check the logs of `ia_data_agent` container using cmd: `docker logs -f ia_data_agent`. One should see, publish messages like `Publishing topic: [topic_name]`

4. To verify the E2E data flow working between IEI running on ECN (Edge Compute Node) and `iei-simple-visualizer`
   app running on the same node or on a diff node, check if the classified images and their respective metadata is been received in the `iei-simple-visualizer` container. Refer [iei-simple-visualizer](https://gitlab.devtools.intel.com/Indu/IEdgeInsights/iei-simple-visualizer.git) for more details.

5. `/opt/intel/iei` root directory gets created - This is the installation path for IEI:
     * `config/` - all the IEI configs reside here.
     * `logs/` - all the IEI logs reside here.
     * `dist_libs/` - is the client external libs distribution package
        * `DataAgentClient` -
            * cpp - consists of gRPC cpp client wrappers, protobuff files and test programs
            * py - consists of gRPC py client wrappers, protobuff files and test programs
        * `DataBusAbstraction` -
            * py - consists of opcua py client wrappers and test programs
     * `secret_store/` - This is the vault's persistent storage wherein IEI secrets are stored in encrypted fashion. This directory is recreated                       on every provision step.
     * `data/` - stores the backup data for persistent imagestore and influxdb

> Note:
1. Few useful docker-compose and docker commands:
     * `docker-compose build` - builds all the service containers. To build a single service container, use `docker-compose build [serv_cont_name]`
     * `docker-compose down` - stops and removes the service containers
     * `docker-compose up -d` - brings up the service containers by picking the changes done in `docker-compose.yml`
     * `docker ps` - check running containers
     * `docker ps -a` - check running and stopped containers
     * `docker stop $(docker ps -a -q)` - stops all the containers
     * `docker rm $(docker ps -a -q)` - removes all the containers. Useful when you run into issue of already container is in use.
     * [docker compose cli](https://docs.docker.com/compose/reference/overview/)
     * [docker compose reference](https://docs.docker.com/compose/compose-file/)
     * [docker cli](https://docs.docker.com/engine/reference/commandline/cli/#configuration-files)
2. If you want to run the docker images separately i.e, one by one, run the command `docker-compose run --no-deps [service_cont_name]` Eg: `docker-compose run --name ia_video_ingestion --no-deps      ia_video_ingestion` to run VI container and the switch `--no-deps` will not bring up it's dependencies mentioned in the docker-compose file. If the container is not launching, there could be
   some issue with entrypoint program which could be overrided by providing this extra switch `--entrypoint /bin/bash` before the service container name in the docker-compose run command above, this would let one inside the container and run the actual entrypoint program from the container's terminal to rootcause the issue. If the container is running and one wants to get inside, use cmd: `docker-compose exec [service_cont_name] /bin/bash` or `docker exec -it [cont_name] /bin/bash`

   **NOTE**: Now that we are encrypting the grpc internal secrets, please don't forget to run the command `source ./set_shared_key_nonce_env_vars.sh` as this sets the key and nonce ENVs needed for           the `docker-compose.yml` file
3. For debug purpose, it becomes essential to send dev team the logs of the build/run scripts to rootcause the issue effectively. This is     where the `tee` command comes to rescue.
4. Best way to check logs of containers is to use command: `docker logs -f [cont_name]`. If one wants to see all the docker-compose service container logs at once, then just run
   `docker-compose logs -f`
5. Run these commands to build & start the client tests container:
   `sudo ./client_tests_startup.sh`
   `docker-compose -f client-tests-compose.yml run --entrypoint /bin/bash ia_client_tests`
