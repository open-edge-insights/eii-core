
Docker compose setup of IEI solution:
=====================================
--------------------------------------

The setup instructions below assume the OS is installed and ready.
If Clearlinux is used, please follow the [docker_setup/clear_linux_setup_guide.md](clear_linux_setup_guide.md) for installing the Clearlinux OS.
Rest of the README will mention steps to be followed in Ubuntu for setting up the Edge insights platform.

## <u>Pre-requisities</u>:

1. Install latest docker cli/docker daemon by following [https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce](https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce). Follow **Install using the repository** and **Install Docker CE (follow first 2 steps)** sections there. Also, follow the manage docker as a non-root user section at [https://docs.docker.com/install/linux/linux-postinstall/](https://docs.docker.com/install/linux/linux-postinstall/) to run docker without sudo

2. Please follow the below steps only if the node/system on which the docker setup is tried out is running behind a HTTP proxy server. If that's not the case, this step can be skipped.

    * Configure proxy settings for docker client to connect to internet and for containers to access internet by following [https://docs.docker.com/network/proxy/](https://docs.docker.com/network/proxy/). One can copy the below json object to ~/.docker/config.json (**Note**: `Depending on the geo location where the system is setup, please use the proxy settings of that geo. This change may not be needed in  non-proxy environment`):

        ```
        {
            "proxies":
                {
                    "default":
                    {
                        "httpProxy": "http://proxy.iind.intel.com:911",
                        "httpsProxy": "http://proxy.iind.intel.com:911",
                        "noProxy": "127.0.0.1,localhost,*.intel.com"
                    }
                }
        }
        ```

    * Configure proxy settings for docker daemon by following the steps at [https://docs.docker.com/config/daemon/systemd/#httphttps-proxy](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy). Use the values for http proxy and https proxy as used above (**Note**: `Depending on the geo location where the system is setup, please use the proxy settings of that geo. This change may not be needed in  non-proxy environment`)

    * If you still see issues of not being able to access internet from container, please update `resolv.conf` file at `docker_setup/resolv.conf`. The `docker_setup/compose_startup.sh` and `docker_setup/deploy/deploy_compose_startup.sh` scripts will re-copy the resolv.conf to `/etc/resolv.conf` to keep it updated across system restarts (**Note**: `This change may not be needed in non-proxy environment`):

        ```
        A. Ubuntu 16.04 and earlier

            For Ubuntu 16.04 and earlier, /etc/resolv.conf was dynamically generated by NetworkManager.

            Comment out the line dns=dnsmasq (with a #) in /etc/NetworkManager/NetworkManager.conf

            Restart the NetworkManager to regenerate /etc/resolv.conf :
            sudo systemctl restart network-manager

            Verify on the host: cat /etc/resolv.conf

        B. Ubuntu 18.04 and later

            Ubuntu 18.04 changed to use systemd-resolved to generate /etc/resolv.conf. Now by default it uses a local DNS cache 127.0.0.53. That will not work inside a container, so Docker will default to Google's 8.8.8.8 DNS server, which may break for people behind a firewall.

            /etc/resolv.conf is actually a symlink (ls -l /etc/resolv.conf) which points to /run/systemd/resolve/stub-resolv.conf (127.0.0.53) by default in Ubuntu 18.04.

            Just change the symlink to point to /run/systemd/resolve/resolv.conf, which lists the real DNS servers:
            sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf

            Verify on the host: cat /etc/resolv.conf
        ```

3. Install `docker-compose` tool by following this [https://docs.docker.com/compose/install/#install-compose](https://docs.docker.com/compose/install/#install-compose)

4. Make sure host machine and docker daemon are configured with below security recommendations. [docker_security_recommendation.md](docker_security_recommendation.md)
   Note: This step is required for the final production setup for full security.

### ** IEI pre-requisites **

1. Copy the PCB demo test videos to the `test_videos` folder under `IEdgeInsights` by using the following commands:

    ```
	cd IEdgeInsights/test_videos
	wget -q http://wheeljack.ch.intel.com/test_videos/pcb_d2000.avi
    ```

2. Clone the a locally maintained [kapacitor repository](https://github.intel.com/IEdgeInsights/kapacitor) inside the `IEdgeInsights` folder by obtaining the command from gerrit/teamforge

    **NOTE**: Please use the git repo of kapacitor as is, the script `build.py` is dependent on that.

3. Download the full package for OpenVINO toolkit for Linux version 2018 R4 from the official website (https://software.intel.com/en-us/openvino-toolkit/choose-download/free-download-linux) and extract it inside IEdgeInsights/DataAnalytics. Post this step a directory named l_openvino_toolkit_xxxxx/ will be present inside DataAnalytics directory.

4. Since docker compose setup publishes ports to host and ia_video_ingestion container runs on host network namespace, please ensure to kill all the dependency and iei processes running locally on the host. One could run this script to do so `sudo ./docker_setup/kill_local_dependency_iei_processes.sh`. This script is not extensively tested, so please use `ps -ef` command to see there are no locally running dependency and iei processes.

## Steps to setup IEI solution on test/factory system

### <u>Configuration</u>

1. All configurable options for IEI goes into [.env](.env) file.
2. All the provisioning related containers goes into [provision-compose.yml](provision-compose.yml)    and IEI containers goes into [docker-compose.yml](docker-compose.yml)
3. Provide the right value for "CONFIG_FILE" in [.env](.env) file for video source.
   1. `factory.json` - value to be used if working with defect video files
   2. `factory_prod.json` (default) - value to be used if working with the camera setup
      1. Update `factory_prod.json` to use the correct ingestors. [Updating Ingestors](https://github.intel.com/IEdgeInsights/IEdgeInsights/blob/master/agent/README.md)

4. `<Factory control App>`Follow [FactoryControlApp/README.md](../FactoryControlApp/README.md) for ingestion configuration
  over MQTT, alarm light and reset button
5. Provide the right value for TPM_ENABLE in [.env](.env) file for using TPM feature. This configuration should be used when the IEI is expected to leverage TPM for storing vault specific secret credentials. If one sets it to false, certain credentials are stored in file system.
    1. `true` -  for enabling the tpm to store credentials
    2. `false` - for disabling the tpm

    **NOTE**: Please use `TPM_ENABLE=true` only on systems where TPM hardware is present OR TPM is enabledusing PTT Firmware in the BIOS.

### <u>Build & Installation</u>

1. Building the iei containers from source

    * Follow below steps to generate certificates, provision and build/start IEI.

        1. Certificates generation:

            Follow [cert-tool/README.md](../cert-tool/README.md) to generate the required certificates/keys.

        2. Provision the secrets to Vault (**present working dir - `<IEdgeInsights>/docker_setup/`**)

            Run the script:
            ```sh
            sudo ./provision_startup.sh <PATH_TO_CERTIFICATES_DIRECTORY> | tee provision_startup.txt
                E.g. sudo ./provision_startup.sh ../cert-tool/Certificates/
            ```
            This will take the inputs from `provision_config.json` & certificates, following which it seal the secrets into the Vault.
            It is responsibility of the Admin to remove the source directory wherein certificates exist.

            **Note**: If the admin wants to update the secrets in the vault, a re-provisioning step needs to be done like below:
            ```sh
            <Take back up of image store, influx or any other data if it is needed in future because provisioning steps deletes all of it>
            <Update the new values into provision_config.json & custom certificates directory if necessary>
            sudo ./provision_startup.sh <PATH_TO_CERTIFICATES_DIRECTORY> | tee provision_startup.txt
            ```

        3. Build and run IEI images as per the dependency order (**present working dir - `<IEdgeInsights>/docker_setup/deploy`**)

            For factory deployments, we want IEI to come up automatically on system boot. For doing this, run the script:
            ```sh
            sudo ./setup_iei.py -a | tee setup_iei_logs.txt
            ```
            This will install IEI as a systemd service in Ubuntu. Post installation, IEI can be started / stopped using commands:
            ```sh
            sudo systemctl stop iei
            sudo systemctl start iei
            ```

            **Note**:
            Developers can make use of the below script:
            ```sh
            sudo ./compose_startup.sh | tee compose_startup.txt
            ```
            Verify all IEI containers coming up and working by following the `Post Installation Verification` steps.

        4. This is an `optional` step where in IEI user wants to build and run IEI images as a redistributable .tar image. This is very helpful
           when one wants to deploy docker images directly instead of building in every system. This step doesn't need a provisioning step to be executed because internally it provisions the system first then setup the IEI.

            Creating The IEI tar Ball (Make sure, the user present in ...docker_setup/deploy/ directory)
            ```sh
            sudo ./setup_iei.py -c | tee create_iei_targz.txt
            ```
            > **Note**:
            > 1. This step will create an file named iei.tar.gz in deploy  directory. Now user need to copy this tar ball to the destination node's preferable directory. Following which user need to execute the below mentioned command for deploying IEI in the target machine.

            Installing the IEI tar Ball ( make sure an untampered iei.tar.gz file present in the current working directory)

            ```sh
            tar xzf iei.tar.gz
            sudo ./setup_iei.py -i -p <PATH OF CERTIFICATES DIR>
            ```
    > **Note**:
    > 1. Please note: `cp -f resolv.conf /etc/resolv.conf` line in `compose_startup.sh` needs to be commented in non-proxy environment before
    > starting it off.

2. Follow [VisualHmiClient/README.md](../VisualHmiClient/README.md) to setup Visual HMI client either natively (due to dependencies, this works
   only on Ubuntu) or dockerized version.

   **Note**: VisualHmiClient is a sample python gRPC/OPCUA client created by us for demonstrating the usage of `ImageStore` and `DataBusAbstraction` distribution libs package. If one wants to develop a similar app, one can make use of the `ImageStore` and `DataBusAbstraction` python clients available at `/opt/intel/iei/dist_libs` to receive classified images and their metadata.

3. If working with video file i.e, `CONFIG_FILE` is set to `factory.json` in [.env](.env), by default the video frames are ingested in loop by
   `ia_video_ingestion` container. One can also restart ia_video_ingestion container manually by running:
   `docker restart ia_video_ingestion`

### Post Installation Verification

1. To check if all the IEI images are built successfully, use cmd: `docker images|grep ia` and
   all containers are running, use cmd: `docker ps` (`one should see all the dependency containers and IEI containers up and running`). If you see issues where the build is failing due to non-reachability to Internet, please ensure you have correctly configured proxy settings and restarted docker service. Even after doing this, if you are running into the same issue, please add below instrcutions to all the dockerfiles in `docker_setup\dockerfiles` at the top after the LABEL instruction and retry the building IEI images:

    ```sh
    ENV http_proxy http://proxy.iind.intel.com:911
    ENV https_proxy http://proxy.iind.intel.com:911
    ```

2. `docker ps` should list the below containers in IEI stack:
    * Dependency containers: log rotate (`ia_log_rotate`)
    * IEI core containers:  DataAgent (`ia_data_agent`), imagestore (`ia_imagestore`), Video Ingestion (`ia_video_ingestion`),
      Data Analytics (`ia_data_analytics`), Telegraf based Data ingestion (`ia_telegraf`) and Factory Control App (`ia_factoryctrl_app`)

    **Note**: If any of the above containers are not listed, always use cmd: `sudo tail -f /opt/intel/iei/logs/consolidatedLogs/iei.log` to find out the reason for container failure

3. To verify if the data pipeline withing IEI is working fine i.e., from ingestion -> classification -> publishing classifed metadata onto the
   databus, then check the logs of `ia_data_agent` container using cmd: `docker logs -f ia_data_agent`. One should see, publish messages like `Publishing topic: [topic_name]`

4. To verify the E2E data flow working between IEI running on ECN (Edge Compute Node) and VisualHmiClient running on the same node or on a diff
   node, check if the classified images and their respective metadata is been received in the VisualHmiClient container. Refer [VisualHmiClient/README.md](../VisualHmiClient/README.md) for more details.

5. `/opt/intel/iei` root directory gets created - This is the installation path for IEI:
     * `config/` - all the IEI configs reside here.
     * `logs/` - all the IEI logs reside here.
     * `dist_libs/` - is the client external libs distribution package
        * `DataAgentClient` -
            * cpp - consists of gRPC cpp client wrappers, protobuff files and test programs
            * py - consists of gRPC py client wrappers, protobuff files and test programs
        * `DataBusAbstraction` -
            * py - consists of opcua py client wrappers and test programs
     * `secret_store/` - This is the vault's persistent storage wherein IEI secrets are stored in encrypted fashion. This directory is recreated                       on every provision step.
     * `data/` - stores the backup data for persistent imagestore and influxdb

> Note:
1. Few useful docker-compose and docker commands:
     * `docker-compose build` - builds all the service containers. To build a single service container, use `docker-compose build [serv_cont_name]`
     * `docker-compose down` - stops and removes the service containers
     * `docker-compose up -d` - brings up the service containers by picking the changes done in `docker-compose.yml`
     * `docker ps` - check running containers
     * `docker ps -a` - check running and stopped containers
     * `docker stop $(docker ps -a -q)` - stops all the containers
     * `docker rm $(docker ps -a -q)` - removes all the containers. Useful when you run into issue of already container is in use.
     * [docker compose cli](https://docs.docker.com/compose/reference/overview/)
     * [docker compose reference](https://docs.docker.com/compose/compose-file/)
     * [docker cli](https://docs.docker.com/engine/reference/commandline/cli/#configuration-files)
2. If you want to run the docker images separately i.e, one by one, run the command `docker-compose run --no-deps [service_cont_name]` Eg: `docker-compose run --name ia_video_ingestion --no-deps      ia_video_ingestion` to run VI container and the switch `--no-deps` will not bring up it's dependencies mentioned in the docker-compose file. If the container is not launching, there could be
   some issue with entrypoint program which could be overrided by providing this extra switch `--entrypoint /bin/bash` before the service container name in the docker-compose run command above, this would let one inside the container and run the actual entrypoint program from the container's terminal to rootcause the issue. If the container is running and one wants to get inside, use cmd: `docker-compose exec [service_cont_name] /bin/bash` or `docker exec -it [cont_name] /bin/bash`

   **NOTE**: Now that we are encrypting the grpc internal secrets, please don't forget to run the command `source ./set_shared_key_nonce_env_vars.sh` as this sets the key and nonce ENVs needed for           the `docker-compose.yml` file
3. For debug purpose, it becomes essential to send dev team the logs of the build/run scripts to rootcause the issue effectively. This is     where the `tee` command comes to rescue.
4. Best way to check logs of containers is to use command: `docker logs -f [cont_name]`. If one wants to see all the docker-compose service container logs at once, then just run
   `docker-compose logs -f`
5. Run these commands to build & start the client tests container:
   `sudo ./client_tests_startup.sh`
   `docker-compose -f client-tests-compose.yml run --entrypoint /bin/bash ia_client_tests`
